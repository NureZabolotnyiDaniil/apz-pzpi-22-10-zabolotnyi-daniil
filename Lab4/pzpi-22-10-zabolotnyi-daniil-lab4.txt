Міністерство освіти і науки України
Харківський національний університет радіоелектроніки


Кафедра програмної інженерії








Лабораторна робота №4
з дисципліни: «Архітектура програмного забезпечення» 








Виконав:
ст. гр. ПЗПІ-22-10
Заболотний Д. М.	Перевірив:
ас. кафедри ПІ
Дашенков Д. С.










Харків 2025
4.1 Стратегія масштабування системи
У межах лабораторної роботи реалізовано горизонтальне масштабування серверної частини (бекенда). Було створено кілька екземплярів одного й того ж сервера (реплік), які виконують однакові функції та обслуговують одночасно запити від різних користувачів.
Таке масштабування дозволяє рівномірно розподіляти навантаження, що особливо важливо під час пікової активності системи або під час стрес-тестування.

4.2 Технічна реалізація
4.2.1 Розгортання середовища
Для реалізації масштабування було використано локальний кластер Kubernetes, розгорнутий за допомогою Minikube на операційній системі Windows. Після встановлення та перевірки працездатності середовища, за допомогою інструментів kubectl і Dashboard було розгорнуто основні компоненти системи. У кластері було створено два окремі сервіси: один відповідає за обробку HTTP-запитів користувачів, інший — за зберігання даних. Серверна частина системи (бекенд) розгортається у вигляді двох одночасно працюючих подів. Це забезпечує можливість обробки запитів кількома копіями застосунку одночасно. Таким чином, вся система складається з незалежних компонентів, кожен з яких можна масштабувати окремо. Взаємодія між сервісами відбувається всередині кластера через внутрішню мережу Kubernetes.


Рисунок 4.1 - Перевірка запуску kubectl get nodes


Рисунок 4.2 - Створення кластеру minikube


Рисунок 4.3 - Перевірка того, що він з’явився


Рисунок 4.4 - Dashboard для роботи з Kubernetes


Рисунок 4.5 - Створені поди


Рисунок 4.6 - Оновлений Dashboard для двох подів

4.3 Аналіз вузьких місць під час навантаження
У ході експериментів було встановлено, що першим ресурсом, який починає обмежувати ефективність роботи системи під час зростання навантаження, є обчислювальні ресурси — зокрема, центральний процесор. При значній кількості запитів спостерігається зростання використання CPU, що впливає на швидкість обробки запитів та стабільність відповіді сервера. 
Оскільки кожна копія бекенду використовує спільну базу даних, потенційно вузьким місцем може також стати продуктивність самої бази даних, однак у межах проведених тестів навантаження на неї не досягло критичного рівня. 
Також варто звернути увагу на можливі обмеження пропускної здатності між подами та сервісами, особливо при використанні NodePort-сервісів, які обмежені мережею хост-машини.

4.4 Опис навантажувального тестування і результати
Для перевірки ефективності реалізованого масштабування було проведено навантажувальне тестування із застосуванням інструмента Locust. Сценарій тестування полягав у симуляції паралельних користувачів, які надсилають запити до кореневої точки сервера. 

Код locustfile.py:
from locust import HttpUser, task

class MyUser(HttpUser):
    @task
    def root(self):
        self.client.get("/") 

Далі для тестувння встановимо Locust та запустимо його (рисунок 4.7). 

Рисунок 4.7 - Запуск Locust

Проведемо тест для 50 користувачів (рисунок 4.8).

Рисунок 4.8 - Запуск тесту при двох подах


Рисунок 4.9 - Результат тесту
